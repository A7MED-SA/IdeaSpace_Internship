"""
Ù†Ø¸Ø§Ù… ØªØ±ØªÙŠØ¨ Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ© Ø§Ù„Ø°ÙƒÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ollama
ÙŠØ³ØªØ®Ø¯Ù… Gemma Ù„Ù„Ù€ LLM Ùˆ embedding-gemma Ù„Ù„Ù€ embeddings
Ù…Ø¹ Cross-Encoder Ù„Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¯Ù‚ÙŠÙ‚
"""

import numpy as np
from sentence_transformers import CrossEncoder
from typing import List, Dict, Tuple
import json
from dataclasses import dataclass
import requests
from sklearn.metrics.pairwise import cosine_similarity

@dataclass
class JobPosting:
    """Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙˆØ¸ÙŠÙØ©"""
    title: str
    description: str
    requirements: str
    
    def get_full_text(self) -> str:
        """Ø¯Ù…Ø¬ ÙƒÙ„ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙˆØ¸ÙŠÙØ©"""
        return f"Job Title: {self.title}\n\nDescription: {self.description}\n\nRequirements: {self.requirements}"

@dataclass
class CV:
    """Ø§Ù„Ø³ÙŠØ±Ø© Ø§Ù„Ø°Ø§ØªÙŠØ©"""
    id: str
    name: str
    content: str
    email: str = ""
    phone: str = ""

@dataclass
class RankedCV:
    """Ø³ÙŠØ±Ø© Ø°Ø§ØªÙŠØ© Ù…Ø¹ Ø§Ù„Ø¯Ø±Ø¬Ø§Øª"""
    cv: CV
    bi_encoder_score: float
    cross_encoder_score: float
    llm_analysis: str = ""
    final_score: float = 0.0


class OllamaClient:
    """Ø¹Ù…ÙŠÙ„ Ù„Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ollama"""
    
    def __init__(self, base_url: str = "http://localhost:11434"):
        self.base_url = base_url
        self.embedding_model = "embeddinggemma:300m"  # Ø£Ùˆ "mxbai-embed-large"
        self.llm_model = "gemma3:1b"
    
    def get_embedding(self, text: str) -> np.ndarray:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ embedding Ù…Ù† Ollama"""
        url = f"{self.base_url}/api/embeddings"
        payload = {
            "model": self.embedding_model,
            "prompt": text
        }
        
        try:
            response = requests.post(url, json=payload, timeout=60)
            response.raise_for_status()
            embedding = response.json()["embedding"]
            return np.array(embedding)
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ embedding: {str(e)}")
            raise
    
    def get_embeddings_batch(self, texts: List[str], show_progress: bool = True) -> np.ndarray:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ embeddings Ù„Ø¹Ø¯Ø© Ù†ØµÙˆØµ"""
        embeddings = []
        total = len(texts)
        
        for i, text in enumerate(texts):
            if show_progress:
                print(f"  Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {i+1}/{total}", end='\r')
            
            embedding = self.get_embedding(text)
            embeddings.append(embedding)
        
        if show_progress:
            print()  # Ø³Ø·Ø± Ø¬Ø¯ÙŠØ¯
        
        return np.array(embeddings)
    
    def generate_text(self, prompt: str, max_tokens: int = 500) -> str:
        """ØªÙˆÙ„ÙŠØ¯ Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemma"""
        url = f"{self.base_url}/api/generate"
        payload = {
            "model": self.llm_model,
            "prompt": prompt,
            "stream": False,
            "options": {
                "num_predict": max_tokens,
                "temperature": 0.7
            }
        }
        
        try:
            response = requests.post(url, json=payload, timeout=120)
            response.raise_for_status()
            return response.json()["response"]
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù†Øµ: {str(e)}")
            return f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {str(e)}"


class CVRankingSystem:
    """Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„ÙƒØ§Ù…Ù„ Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ©"""
    
    def __init__(
        self,
        ollama_url: str = "http://localhost:11434",
        cross_encoder_model: str = "cross-encoder/ms-marco-MiniLM-L-6-v2",
        use_llm: bool = True,
        top_k_bi_encoder: int = 20
    ):
        """
        ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
        
        Args:
            ollama_url: Ø¹Ù†ÙˆØ§Ù† Ø®Ø§Ø¯Ù… Ollama
            cross_encoder_model: Ù†Ù…ÙˆØ°Ø¬ Cross-Encoder Ù„Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ±ØªÙŠØ¨
            use_llm: Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemma Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
            top_k_bi_encoder: Ø¹Ø¯Ø¯ Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ© Ø§Ù„Ù…Ø¨Ø¯Ø¦ÙŠØ©
        """
        print("ğŸ”„ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù…...")
        
        # ØªÙ‡ÙŠØ¦Ø© Ollama Client
        self.ollama = OllamaClient(base_url=ollama_url)
        
        # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Ollama
        try:
            test_embedding = self.ollama.get_embedding("test")
            print(f"âœ… ØªÙ… Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Ollama Ø¨Ù†Ø¬Ø§Ø­! (Embedding model: {self.ollama.embedding_model})")
        except Exception as e:
            print(f"âŒ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Ollama: {str(e)}")
            print("âš ï¸ ØªØ£ÙƒØ¯ Ù…Ù† ØªØ´ØºÙŠÙ„ Ollama: ollama serve")
            raise
        
        # ØªØ­Ù…ÙŠÙ„ Cross-Encoder
        print("ğŸ”„ ØªØ­Ù…ÙŠÙ„ Cross-Encoder...")
        self.cross_encoder = CrossEncoder(cross_encoder_model)
        print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Cross-Encoder: {cross_encoder_model}")
        
        self.use_llm = use_llm
        self.top_k = top_k_bi_encoder
        
        if self.use_llm:
            print(f"âœ… ØªÙ… ØªÙØ¹ÙŠÙ„ LLM Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… (Model: {self.ollama.llm_model})")
        
        print("âœ… Ø§Ù„Ù†Ø¸Ø§Ù… Ø¬Ø§Ù‡Ø² Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…!")
    
    def encode_job(self, job: JobPosting) -> np.ndarray:
        """ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø¥Ù„Ù‰ embedding Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ollama"""
        job_text = job.get_full_text()
        print("ğŸ”„ ØªØ­ÙˆÙŠÙ„ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø¥Ù„Ù‰ embedding...")
        return self.ollama.get_embedding(job_text)
    
    def encode_cvs(self, cvs: List[CV]) -> np.ndarray:
        """ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ© Ø¥Ù„Ù‰ embeddings"""
        print(f"ğŸ”„ ØªØ­ÙˆÙŠÙ„ {len(cvs)} Ø³ÙŠØ±Ø© Ø°Ø§ØªÙŠØ© Ø¥Ù„Ù‰ embeddings...")
        cv_texts = [cv.content for cv in cvs]
        return self.ollama.get_embeddings_batch(cv_texts, show_progress=True)
    
    def bi_encoder_search(
        self,
        job_embedding: np.ndarray,
        cv_embeddings: np.ndarray,
        cvs: List[CV]
    ) -> List[Tuple[CV, float]]:
        """
        Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø£ÙˆÙ„ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… embeddings (Ø³Ø±ÙŠØ¹)
        ÙŠØ­Ø³Ø¨ cosine similarity Ø¨ÙŠÙ† Ø§Ù„ÙˆØ¸ÙŠÙØ© ÙˆØ§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ©
        """
        print(f"\nğŸ” Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø£ÙˆÙ„ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Embeddings...")
        
        # Ø­Ø³Ø§Ø¨ cosine similarity
        job_embedding_2d = job_embedding.reshape(1, -1)
        similarities = cosine_similarity(job_embedding_2d, cv_embeddings)[0]
        
        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        top_indices = np.argsort(similarities)[::-1][:self.top_k]
        results = [(cvs[idx], float(similarities[idx])) for idx in top_indices]
        
        print(f"âœ… ØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ {len(results)} Ø³ÙŠØ±Ø© Ø°Ø§ØªÙŠØ©")
        return results
    
    def cross_encoder_rerank(
        self,
        job: JobPosting,
        candidate_cvs: List[Tuple[CV, float]]
    ) -> List[RankedCV]:
        """
        Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ±ØªÙŠØ¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Cross-Encoder (Ø£ÙƒØ«Ø± Ø¯Ù‚Ø©)
        """
        print(f"\nğŸ¯ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ±ØªÙŠØ¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Cross-Encoder...")
        
        job_text = job.get_full_text()
        pairs = [[job_text, cv.content] for cv, _ in candidate_cvs]
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ø±Ø¬Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Cross-Encoder
        print("  Ø¬Ø§Ø±ÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ø±Ø¬Ø§Øª...")
        cross_scores = self.cross_encoder.predict(pairs)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¦Ù…Ø© Ù…Ø±ØªØ¨Ø©
        ranked_cvs = []
        for (cv, bi_score), cross_score in zip(candidate_cvs, cross_scores):
            ranked_cv = RankedCV(
                cv=cv,
                bi_encoder_score=bi_score,
                cross_encoder_score=float(cross_score),
                final_score=float(cross_score)
            )
            ranked_cvs.append(ranked_cv)
        
        # ØªØ±ØªÙŠØ¨ ØªÙ†Ø§Ø²Ù„ÙŠ Ø­Ø³Ø¨ Ø§Ù„Ø¯Ø±Ø¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        ranked_cvs.sort(key=lambda x: x.final_score, reverse=True)
        
        print(f"âœ… ØªÙ… Ø¥Ø¹Ø§Ø¯Ø© ØªØ±ØªÙŠØ¨ Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ© Ø¨Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©")
        return ranked_cvs
    
    def llm_analysis(
        self,
        job: JobPosting,
        ranked_cvs: List[RankedCV],
        top_n: int = 5
    ) -> List[RankedCV]:
        """
        ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemma Ù„Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ© Ø§Ù„Ø£ÙØ¶Ù„
        """
        if not self.use_llm:
            print("âš ï¸ ØªÙ… ØªØ®Ø·ÙŠ ØªØ­Ù„ÙŠÙ„ LLM")
            return ranked_cvs
        
        print(f"\nğŸ¤– Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3: Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemma Ù„Ø£ÙØ¶Ù„ {top_n} Ø³ÙŠØ± Ø°Ø§ØªÙŠØ©...")
        
        for i, ranked_cv in enumerate(ranked_cvs[:top_n]):
            try:
                # ØªØ­Ø¯ÙŠØ¯ Ø·ÙˆÙ„ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø³ÙŠØ±Ø© Ø§Ù„Ø°Ø§ØªÙŠØ© (Ù„ØªØ¬Ù†Ø¨ ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ø¯)
                cv_content = ranked_cv.cv.content[:1500]
                
                prompt = f"""You are an expert HR recruiter. Analyze how well this CV matches the job posting.

Job Posting:
{job.get_full_text()}

CV:
{cv_content}

Provide a concise analysis (3-4 lines) covering:
1. Main strengths
2. Matching skills
3. Any gaps or weaknesses
4. Overall assessment (Excellent/Very Good/Good/Fair/Poor)

Analysis:"""

                print(f"  ğŸ”„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠØ±Ø© Ø§Ù„Ø°Ø§ØªÙŠØ© {i+1}/{top_n}...", end='')
                analysis = self.ollama.generate_text(prompt, max_tokens=300)
                ranked_cv.llm_analysis = analysis.strip()
                print(" âœ…")
                
            except Exception as e:
                print(f" âŒ")
                print(f"  âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠØ±Ø© {i+1}: {str(e)}")
                ranked_cv.llm_analysis = "Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ø³Ø¨Ø¨ Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ"
        
        return ranked_cvs
    
    def rank_cvs(
        self,
        job: JobPosting,
        cvs: List[CV],
        use_llm_analysis: bool = None
    ) -> List[RankedCV]:
        """
        Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©: ØªØ±ØªÙŠØ¨ Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ© Ø¨Ø§Ù„ÙƒØ§Ù…Ù„
        
        Args:
            job: Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙˆØ¸ÙŠÙØ©
            cvs: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ©
            use_llm_analysis: Ø§Ø³ØªØ®Ø¯Ø§Ù… LLM Ù„Ù„ØªØ­Ù„ÙŠÙ„ (None = Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ)
        
        Returns:
            Ù‚Ø§Ø¦Ù…Ø© Ù…Ø±ØªØ¨Ø© Ù…Ù† Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ© Ù…Ø¹ Ø§Ù„Ø¯Ø±Ø¬Ø§Øª ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„
        """
        print("="*70)
        print("ğŸš€ Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© ØªØ±ØªÙŠØ¨ Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ©")
        print("="*70)
        
        # 1. Embeddings: Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø³Ø±ÙŠØ¹
        job_embedding = self.encode_job(job)
        cv_embeddings = self.encode_cvs(cvs)
        candidate_cvs = self.bi_encoder_search(job_embedding, cv_embeddings, cvs)
        
        # 2. Cross-Encoder: Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¯Ù‚ÙŠÙ‚
        ranked_cvs = self.cross_encoder_rerank(job, candidate_cvs)
        
        # 3. Gemma LLM: Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
        if use_llm_analysis is None:
            use_llm_analysis = self.use_llm
        
        if use_llm_analysis:
            ranked_cvs = self.llm_analysis(job, ranked_cvs)
        
        print("\n" + "="*70)
        print("âœ… Ø§ÙƒØªÙ…Ù„Øª Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ±ØªÙŠØ¨ Ø¨Ù†Ø¬Ø§Ø­!")
        print("="*70)
        
        return ranked_cvs
    
    def print_results(self, ranked_cvs: List[RankedCV], top_n: int = 10):
        """Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨Ø´ÙƒÙ„ Ù…Ù†Ø³Ù‚"""
        print(f"\nğŸ“Š Ø£ÙØ¶Ù„ {min(top_n, len(ranked_cvs))} Ø³ÙŠØ± Ø°Ø§ØªÙŠØ©:")
        print("="*80)
        
        for i, ranked_cv in enumerate(ranked_cvs[:top_n], 1):
            print(f"\nğŸ† Ø§Ù„Ù…Ø±ØªØ¨Ø© {i}:")
            print(f"   Ø§Ù„Ø§Ø³Ù…: {ranked_cv.cv.name}")
            print(f"   ID: {ranked_cv.cv.id}")
            if ranked_cv.cv.email:
                print(f"   Email: {ranked_cv.cv.email}")
            print(f"   Ø¯Ø±Ø¬Ø© Embedding: {ranked_cv.bi_encoder_score:.4f}")
            print(f"   Ø¯Ø±Ø¬Ø© Cross-Encoder: {ranked_cv.cross_encoder_score:.4f}")
            print(f"   Ø§Ù„Ø¯Ø±Ø¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©: {ranked_cv.final_score:.4f}")
            
            if ranked_cv.llm_analysis:
                print(f"\n   ğŸ“ ØªØ­Ù„ÙŠÙ„ Gemma:")
                for line in ranked_cv.llm_analysis.split('\n'):
                    if line.strip():
                        print(f"      {line.strip()}")
            
            print("-"*80)
    
    def save_results(self, ranked_cvs: List[RankedCV], filename: str = "cv_ranking_results.json"):
        """Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ù…Ù„Ù JSON"""
        results_dict = []
        for rank, ranked_cv in enumerate(ranked_cvs, 1):
            results_dict.append({
                "rank": rank,
                "name": ranked_cv.cv.name,
                "id": ranked_cv.cv.id,
                "email": ranked_cv.cv.email,
                "phone": ranked_cv.cv.phone,
                "embedding_score": round(ranked_cv.bi_encoder_score, 4),
                "cross_encoder_score": round(ranked_cv.cross_encoder_score, 4),
                "final_score": round(ranked_cv.final_score, 4),
                "llm_analysis": ranked_cv.llm_analysis
            })
        
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(results_dict, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ: {filename}")


# =============================================================================
# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
# =============================================================================

def main():
    """Ù…Ø«Ø§Ù„ Ø¹Ù…Ù„ÙŠ Ø¹Ù„Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ø¸Ø§Ù…"""
    
    # 1. Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙˆØ¸ÙŠÙØ©
    job = JobPosting(
        title="Senior Python Developer",
        description="""
        We are looking for an experienced Python developer to join our team.
        You will work on building scalable web applications using Django and FastAPI.
        Experience with machine learning and NLP is a plus.
        """,
        requirements="""
        - 5+ years of Python development experience
        - Strong knowledge of Django/FastAPI
        - Experience with PostgreSQL and Redis
        - Familiarity with Docker and Kubernetes
        - Good understanding of ML/NLP concepts
        - Excellent problem-solving skills
        """
    )
    
    # 2. Ø¥Ù†Ø´Ø§Ø¡ Ø³ÙŠØ± Ø°Ø§ØªÙŠØ© ØªØ¬Ø±ÙŠØ¨ÙŠØ©
    cvs = [
        CV(
            id="CV001",
            name="Ahmed Mohamed",
            content="""
            Senior Software Engineer with 6 years of experience in Python development.
            Expert in Django, FastAPI, and RESTful APIs. Built multiple scalable web applications
            serving millions of users. Proficient in PostgreSQL, Redis, and MongoDB.
            Experience with Docker, Kubernetes, and AWS. Strong background in machine learning
            and natural language processing. Led team of 5 developers in previous role.
            Skills: Python, Django, FastAPI, PostgreSQL, Redis, Docker, Kubernetes, ML, NLP, AWS
            """,
            email="ahmed@example.com",
            phone="+20 123 456 7890"
        ),
        CV(
            id="CV002",
            name="Sara Ali",
            content="""
            Python Developer with 3 years of experience. Worked primarily with Flask and Django.
            Good knowledge of SQL databases and basic understanding of Docker.
            Recent graduate with Master's degree in Computer Science.
            Interested in learning more about cloud technologies.
            Skills: Python, Django, Flask, MySQL, Git, Basic Docker
            """,
            email="sara@example.com",
            phone="+20 100 111 2222"
        ),
        CV(
            id="CV003",
            name="Omar Hassan",
            content="""
            Full Stack Developer with 7 years experience. Expert in Python, JavaScript, React.
            Built enterprise applications using Django and Node.js. Strong DevOps skills
            including Docker, Kubernetes, CI/CD pipelines. Experience with ML model deployment
            and MLOps. Contributed to several open-source NLP projects. AWS Certified Solutions Architect.
            Skills: Python, Django, FastAPI, React, Node.js, PostgreSQL, Redis, Docker, Kubernetes, ML, NLP, AWS, MLOps
            """,
            email="omar@example.com",
            phone="+20 122 333 4444"
        ),
        CV(
            id="CV004",
            name="Fatima Khalil",
            content="""
            Junior Python Developer with 1 year of experience. Knowledge of basic Python
            and Flask framework. Completed online courses in web development.
            Eager to learn and grow in the field. Strong academic background.
            Skills: Python, Flask, HTML, CSS, JavaScript, Git
            """,
            email="fatima@example.com",
            phone="+20 111 222 3333"
        ),
        CV(
            id="CV005",
            name="Khaled Ibrahim",
            content="""
            AI/ML Engineer with 5 years experience specializing in NLP and deep learning.
            Proficient in Python, TensorFlow, PyTorch, and scikit-learn. Built chatbots
            and text classification systems. Good knowledge of FastAPI for model serving.
            Experience with Docker and basic DevOps. Published research papers in NLP.
            Skills: Python, TensorFlow, PyTorch, scikit-learn, FastAPI, NLP, Deep Learning, Docker
            """,
            email="khaled@example.com",
            phone="+20 155 666 7777"
        ),
        CV(
            id="CV006",
            name="Layla Hussein",
            content="""
            Backend Developer with 4 years experience. Specialized in Python and Go.
            Built microservices architecture using FastAPI and gRPC. Good experience with
            distributed systems and message queues (RabbitMQ, Kafka). Knowledge of PostgreSQL,
            MongoDB, and Redis. Familiar with Docker and Kubernetes.
            Skills: Python, Go, FastAPI, gRPC, PostgreSQL, MongoDB, Redis, Docker, Kubernetes, Microservices
            """,
            email="layla@example.com",
            phone="+20 101 888 9999"
        )
    ]
    
    # 3. ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
    # ØªØ£ÙƒØ¯ Ù…Ù† ØªØ´ØºÙŠÙ„ Ollama Ø£ÙˆÙ„Ø§Ù‹: ollama serve
    # ÙˆØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: ollama pull gemma2 && ollama pull nomic-embed-text
    
    try:
        system = CVRankingSystem(
            ollama_url="http://localhost:11434",
            use_llm=True,  # ØªÙØ¹ÙŠÙ„ Gemma Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
            top_k_bi_encoder=10  # Ø¹Ø¯Ø¯ Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ù…Ø¨Ø¯Ø¦ÙŠØ©
        )
        
        # 4. ØªØ±ØªÙŠØ¨ Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ©
        ranked_results = system.rank_cvs(job, cvs, use_llm_analysis=True)
        
        # 5. Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        system.print_results(ranked_results, top_n=6)
        
        # 6. Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        system.save_results(ranked_results)
        
    except Exception as e:
        print(f"\nâŒ Ø­Ø¯Ø« Ø®Ø·Ø£: {str(e)}")
        print("\nğŸ’¡ ØªØ£ÙƒØ¯ Ù…Ù†:")
        print("   1. ØªØ´ØºÙŠÙ„ Ollama: ollama serve")
        print("   2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬:")
        print("      - ollama pull gemma2")
        print("      - ollama pull nomic-embed-text")


if __name__ == "__main__":
    main()