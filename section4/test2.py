"""
Ù†Ø¸Ø§Ù… ØªØ±ØªÙŠØ¨ Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ© Ø§Ù„Ø°ÙƒÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ollama
ÙŠØ³ØªØ®Ø¯Ù… Gemma Ù„Ù„Ù€ LLM Ùˆ embedding-gemma Ù„Ù„Ù€ embeddings
Ù…Ø¹ Cross-Encoder Ù„Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¯Ù‚ÙŠÙ‚
"""

import numpy as np
from sentence_transformers import CrossEncoder
from typing import List, Dict, Tuple
import json
from dataclasses import dataclass
import requests
from sklearn.metrics.pairwise import cosine_similarity

@dataclass
class JobPosting:
    """Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙˆØ¸ÙŠÙØ©"""
    title: str
    description: str
    requirements: str
    
    def get_full_text(self) -> str:
        """Ø¯Ù…Ø¬ ÙƒÙ„ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙˆØ¸ÙŠÙØ©"""
        return f"Job Title: {self.title}\n\nDescription: {self.description}\n\nRequirements: {self.requirements}"

@dataclass
class CV:
    """Ø§Ù„Ø³ÙŠØ±Ø© Ø§Ù„Ø°Ø§ØªÙŠØ©"""
    id: str
    name: str
    content: str
    email: str = ""
    phone: str = ""

@dataclass
class RankedCV:
    """Ø³ÙŠØ±Ø© Ø°Ø§ØªÙŠØ© Ù…Ø¹ Ø§Ù„Ø¯Ø±Ø¬Ø§Øª"""
    cv: CV
    bi_encoder_score: float
    cross_encoder_score: float
    llm_analysis: str = ""
    final_score: float = 0.0


class OllamaClient:
    """Ø¹Ù…ÙŠÙ„ Ù„Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ollama"""
    
    def __init__(self, base_url: str = "http://localhost:11434"):
        self.base_url = base_url
        self.embedding_model = "nomic-embed-text:latest"  # Ø£Ùˆ "mxbai-embed-large"
        self.llm_model = "gemma3:1b"
    
    def get_embedding(self, text: str) -> np.ndarray:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ embedding Ù…Ù† Ollama"""
        url = f"{self.base_url}/api/embeddings"
        payload = {
            "model": self.embedding_model,
            "prompt": text
        }
        
        try:
            response = requests.post(url, json=payload, timeout=60)
            response.raise_for_status()
            embedding = response.json()["embedding"]
            return np.array(embedding)
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ embedding: {str(e)}")
            raise
    
    def get_embeddings_batch(self, texts: List[str], show_progress: bool = True) -> np.ndarray:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ embeddings Ù„Ø¹Ø¯Ø© Ù†ØµÙˆØµ"""
        embeddings = []
        total = len(texts)
        
        for i, text in enumerate(texts):
            if show_progress:
                print(f"  Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {i+1}/{total}", end='\r')
            
            embedding = self.get_embedding(text)
            embeddings.append(embedding)
        
        if show_progress:
            print()  # Ø³Ø·Ø± Ø¬Ø¯ÙŠØ¯
        
        return np.array(embeddings)
    
    def generate_text(self, prompt: str, max_tokens: int = 500) -> str:
        """ØªÙˆÙ„ÙŠØ¯ Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemma"""
        url = f"{self.base_url}/api/generate"
        payload = {
            "model": self.llm_model,
            "prompt": prompt,
            "stream": False,
            "options": {
                "num_predict": max_tokens,
                "temperature": 0.7
            }
        }
        
        try:
            response = requests.post(url, json=payload, timeout=120)
            response.raise_for_status()
            return response.json()["response"]
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù†Øµ: {str(e)}")
            return f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {str(e)}"


class CVRankingSystem:
    """Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„ÙƒØ§Ù…Ù„ Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ©"""
    
    def __init__(
        self,
        ollama_url: str = "http://localhost:11434",
        cross_encoder_model: str = "cross-encoder/ms-marco-MiniLM-L-6-v2",
        use_llm: bool = True,
        top_k_bi_encoder: int = 20
    ):
        """
        ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
        
        Args:
            ollama_url: Ø¹Ù†ÙˆØ§Ù† Ø®Ø§Ø¯Ù… Ollama
            cross_encoder_model: Ù†Ù…ÙˆØ°Ø¬ Cross-Encoder Ù„Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ±ØªÙŠØ¨
            use_llm: Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemma Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
            top_k_bi_encoder: Ø¹Ø¯Ø¯ Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ© Ø§Ù„Ù…Ø¨Ø¯Ø¦ÙŠØ©
        """
        print("ğŸ”„ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù…...")
        
        # ØªÙ‡ÙŠØ¦Ø© Ollama Client
        self.ollama = OllamaClient(base_url=ollama_url)
        
        # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Ollama
        try:
            test_embedding = self.ollama.get_embedding("test")
            print(f"âœ… ØªÙ… Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Ollama Ø¨Ù†Ø¬Ø§Ø­! (Embedding model: {self.ollama.embedding_model})")
        except Exception as e:
            print(f"âŒ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Ollama: {str(e)}")
            print("âš ï¸ ØªØ£ÙƒØ¯ Ù…Ù† ØªØ´ØºÙŠÙ„ Ollama: ollama serve")
            raise
        
        # ØªØ­Ù…ÙŠÙ„ Cross-Encoder
        print("ğŸ”„ ØªØ­Ù…ÙŠÙ„ Cross-Encoder...")
        self.cross_encoder = CrossEncoder(cross_encoder_model)
        print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Cross-Encoder: {cross_encoder_model}")
        
        self.use_llm = use_llm
        self.top_k = top_k_bi_encoder
        
        if self.use_llm:
            print(f"âœ… ØªÙ… ØªÙØ¹ÙŠÙ„ LLM Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… (Model: {self.ollama.llm_model})")
        
        print("âœ… Ø§Ù„Ù†Ø¸Ø§Ù… Ø¬Ø§Ù‡Ø² Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…!")
    
    def encode_job(self, job: JobPosting) -> np.ndarray:
        """ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø¥Ù„Ù‰ embedding Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ollama"""
        job_text = job.get_full_text()
        print("ğŸ”„ ØªØ­ÙˆÙŠÙ„ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø¥Ù„Ù‰ embedding...")
        return self.ollama.get_embedding(job_text)
    
    def encode_cvs(self, cvs: List[CV]) -> np.ndarray:
        """ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ© Ø¥Ù„Ù‰ embeddings"""
        print(f"ğŸ”„ ØªØ­ÙˆÙŠÙ„ {len(cvs)} Ø³ÙŠØ±Ø© Ø°Ø§ØªÙŠØ© Ø¥Ù„Ù‰ embeddings...")
        cv_texts = [cv.content for cv in cvs]
        return self.ollama.get_embeddings_batch(cv_texts, show_progress=True)
    
    def bi_encoder_search(
        self,
        job_embedding: np.ndarray,
        cv_embeddings: np.ndarray,
        cvs: List[CV]
    ) -> List[Tuple[CV, float]]:
        """
        Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø£ÙˆÙ„ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… embeddings (Ø³Ø±ÙŠØ¹)
        ÙŠØ­Ø³Ø¨ cosine similarity Ø¨ÙŠÙ† Ø§Ù„ÙˆØ¸ÙŠÙØ© ÙˆØ§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ©
        """
        print(f"\nğŸ” Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø£ÙˆÙ„ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Embeddings...")
        
        # Ø­Ø³Ø§Ø¨ cosine similarity
        job_embedding_2d = job_embedding.reshape(1, -1)
        similarities = cosine_similarity(job_embedding_2d, cv_embeddings)[0]
        
        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        top_indices = np.argsort(similarities)[::-1][:self.top_k]
        results = [(cvs[idx], float(similarities[idx])) for idx in top_indices]
        
        print(f"âœ… ØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ {len(results)} Ø³ÙŠØ±Ø© Ø°Ø§ØªÙŠØ©")
        return results
    
    def cross_encoder_rerank(
        self,
        job: JobPosting,
        candidate_cvs: List[Tuple[CV, float]]
    ) -> List[RankedCV]:
        """
        Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ±ØªÙŠØ¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Cross-Encoder (Ø£ÙƒØ«Ø± Ø¯Ù‚Ø©)
        """
        print(f"\nğŸ¯ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ±ØªÙŠØ¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Cross-Encoder...")
        
        job_text = job.get_full_text()
        pairs = [[job_text, cv.content] for cv, _ in candidate_cvs]
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ø±Ø¬Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Cross-Encoder
        print("  Ø¬Ø§Ø±ÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ø±Ø¬Ø§Øª...")
        cross_scores = self.cross_encoder.predict(pairs)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¦Ù…Ø© Ù…Ø±ØªØ¨Ø©
        ranked_cvs = []
        for (cv, bi_score), cross_score in zip(candidate_cvs, cross_scores):
            ranked_cv = RankedCV(
                cv=cv,
                bi_encoder_score=bi_score,
                cross_encoder_score=float(cross_score),
                final_score=float(cross_score)
            )
            ranked_cvs.append(ranked_cv)
        
        # ØªØ±ØªÙŠØ¨ ØªÙ†Ø§Ø²Ù„ÙŠ Ø­Ø³Ø¨ Ø§Ù„Ø¯Ø±Ø¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        ranked_cvs.sort(key=lambda x: x.final_score, reverse=True)
        
        print(f"âœ… ØªÙ… Ø¥Ø¹Ø§Ø¯Ø© ØªØ±ØªÙŠØ¨ Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ© Ø¨Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©")
        return ranked_cvs
    
    def llm_analysis(
        self,
        job: JobPosting,
        ranked_cvs: List[RankedCV],
        top_n: int = 5
    ) -> List[RankedCV]:
        """
        ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemma Ù„Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ© Ø§Ù„Ø£ÙØ¶Ù„
        """
        if not self.use_llm:
            print("âš ï¸ ØªÙ… ØªØ®Ø·ÙŠ ØªØ­Ù„ÙŠÙ„ LLM")
            return ranked_cvs
        
        print(f"\nğŸ¤– Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3: Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemma Ù„Ø£ÙØ¶Ù„ {top_n} Ø³ÙŠØ± Ø°Ø§ØªÙŠØ©...")
        
        for i, ranked_cv in enumerate(ranked_cvs[:top_n]):
            try:
                # ØªØ­Ø¯ÙŠØ¯ Ø·ÙˆÙ„ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø³ÙŠØ±Ø© Ø§Ù„Ø°Ø§ØªÙŠØ© (Ù„ØªØ¬Ù†Ø¨ ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ø¯)
                cv_content = ranked_cv.cv.content[:1500]
                
                prompt = f"""You are an expert HR recruiter. Analyze how well this CV matches the job posting.

Job Posting:
{job.get_full_text()}

CV:
{cv_content}

Provide a concise analysis (3-4 lines) covering:
1. Main strengths
2. Matching skills
3. Any gaps or weaknesses
4. Overall assessment (Excellent/Very Good/Good/Fair/Poor)

Analysis:"""

                print(f"  ğŸ”„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠØ±Ø© Ø§Ù„Ø°Ø§ØªÙŠØ© {i+1}/{top_n}...", end='')
                analysis = self.ollama.generate_text(prompt, max_tokens=300)
                ranked_cv.llm_analysis = analysis.strip()
                print(" âœ…")
                
            except Exception as e:
                print(f" âŒ")
                print(f"  âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠØ±Ø© {i+1}: {str(e)}")
                ranked_cv.llm_analysis = "Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ø³Ø¨Ø¨ Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ"
        
        return ranked_cvs
    
    def rank_cvs(
        self,
        job: JobPosting,
        cvs: List[CV],
        use_llm_analysis: bool = None
    ) -> List[RankedCV]:
        """
        Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©: ØªØ±ØªÙŠØ¨ Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ© Ø¨Ø§Ù„ÙƒØ§Ù…Ù„
        
        Args:
            job: Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙˆØ¸ÙŠÙØ©
            cvs: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ©
            use_llm_analysis: Ø§Ø³ØªØ®Ø¯Ø§Ù… LLM Ù„Ù„ØªØ­Ù„ÙŠÙ„ (None = Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ)
        
        Returns:
            Ù‚Ø§Ø¦Ù…Ø© Ù…Ø±ØªØ¨Ø© Ù…Ù† Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ© Ù…Ø¹ Ø§Ù„Ø¯Ø±Ø¬Ø§Øª ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„
        """
        print("="*70)
        print("ğŸš€ Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© ØªØ±ØªÙŠØ¨ Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ©")
        print("="*70)
        
        # 1. Embeddings: Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø³Ø±ÙŠØ¹
        job_embedding = self.encode_job(job)
        cv_embeddings = self.encode_cvs(cvs)
        candidate_cvs = self.bi_encoder_search(job_embedding, cv_embeddings, cvs)
        
        # 2. Cross-Encoder: Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¯Ù‚ÙŠÙ‚
        ranked_cvs = self.cross_encoder_rerank(job, candidate_cvs)
        
        # 3. Gemma LLM: Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
        if use_llm_analysis is None:
            use_llm_analysis = self.use_llm
        
        if use_llm_analysis:
            ranked_cvs = self.llm_analysis(job, ranked_cvs)
        
        print("\n" + "="*70)
        print("âœ… Ø§ÙƒØªÙ…Ù„Øª Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ±ØªÙŠØ¨ Ø¨Ù†Ø¬Ø§Ø­!")
        print("="*70)
        
        return ranked_cvs
    
    def print_results(self, ranked_cvs: List[RankedCV], top_n: int = 10):
        """Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨Ø´ÙƒÙ„ Ù…Ù†Ø³Ù‚"""
        print(f"\nğŸ“Š Ø£ÙØ¶Ù„ {min(top_n, len(ranked_cvs))} Ø³ÙŠØ± Ø°Ø§ØªÙŠØ©:")
        print("="*80)
        
        for i, ranked_cv in enumerate(ranked_cvs[:top_n], 1):
            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£ÙŠÙ‚ÙˆÙ†Ø© Ø­Ø³Ø¨ Ø§Ù„Ø¯Ø±Ø¬Ø©
            if ranked_cv.final_score >= 2.0:
                icon = "ğŸ¥‡"
            elif ranked_cv.final_score >= 0.5:
                icon = "ğŸ¥ˆ"
            elif ranked_cv.final_score >= 0:
                icon = "ğŸ¥‰"
            else:
                icon = "ğŸ“„"
            
            print(f"\n{icon} Ø§Ù„Ù…Ø±ØªØ¨Ø© {i}:")
            print(f"   Ø§Ù„Ø§Ø³Ù…: {ranked_cv.cv.name}")
            print(f"   ID: {ranked_cv.cv.id}")
            if ranked_cv.cv.email:
                print(f"   Email: {ranked_cv.cv.email}")
            print(f"   Ø¯Ø±Ø¬Ø© Embedding: {ranked_cv.bi_encoder_score:.4f}")
            print(f"   Ø¯Ø±Ø¬Ø© Cross-Encoder: {ranked_cv.cross_encoder_score:.4f}")
            print(f"   â­ Ø§Ù„Ø¯Ø±Ø¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©: {ranked_cv.final_score:.4f}")
            
            if ranked_cv.llm_analysis:
                print(f"\n   ğŸ“ ØªØ­Ù„ÙŠÙ„ Gemma:")
                # ØªÙ†Ø¸ÙŠÙ ÙˆØªÙ‚ØµÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„
                analysis = ranked_cv.llm_analysis.strip()
                # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„Ù…ÙƒØ±Ø±Ø© Ø£Ùˆ ØºÙŠØ± Ø§Ù„Ù…ÙÙŠØ¯Ø©
                if "Overall Assessment:" in analysis:
                    analysis = analysis.split("Overall Assessment:")[0] + "Overall Assessment:" + analysis.split("Overall Assessment:")[-1].split("\n")[0]
                
                for line in analysis.split('\n')[:10]:  # Ø£ÙˆÙ„ 10 Ø£Ø³Ø·Ø± ÙÙ‚Ø·
                    if line.strip() and not line.strip().startswith("---"):
                        print(f"      {line.strip()}")
            else:
                print(f"\n   âš ï¸ Ù„Ù… ÙŠØªÙ… ØªØ­Ù„ÙŠÙ„ Ù‡Ø°Ù‡ Ø§Ù„Ø³ÙŠØ±Ø© Ø§Ù„Ø°Ø§ØªÙŠØ©")
            
            print("-"*80)
    
    def save_results(self, ranked_cvs: List[RankedCV], filename: str = "cv_ranking_results.json"):
        """Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ù…Ù„Ù JSON"""
        results_dict = []
        for rank, ranked_cv in enumerate(ranked_cvs, 1):
            results_dict.append({
                "rank": rank,
                "name": ranked_cv.cv.name,
                "id": ranked_cv.cv.id,
                "email": ranked_cv.cv.email,
                "phone": ranked_cv.cv.phone,
                "embedding_score": round(ranked_cv.bi_encoder_score, 4),
                "cross_encoder_score": round(ranked_cv.cross_encoder_score, 4),
                "final_score": round(ranked_cv.final_score, 4),
                "llm_analysis": ranked_cv.llm_analysis
            })
        
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(results_dict, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ: {filename}")
    
    def analyze_ranking(self, ranked_cvs: List[RankedCV]):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØ´Ø±Ø­ Ø§Ù„ØªØ±ØªÙŠØ¨"""
        print("\n" + "="*80)
        print("ğŸ“ˆ ØªØ­Ù„ÙŠÙ„ Ø¥Ø­ØµØ§Ø¦ÙŠ Ù„Ù„Ù†ØªØ§Ø¦Ø¬")
        print("="*80)
        
        embedding_scores = [cv.bi_encoder_score for cv in ranked_cvs]
        cross_scores = [cv.cross_encoder_score for cv in ranked_cvs]
        
        print(f"\nğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Embedding Scores:")
        print(f"   Ø§Ù„Ù…ØªÙˆØ³Ø·: {np.mean(embedding_scores):.4f}")
        print(f"   Ø§Ù„Ø£Ø¹Ù„Ù‰: {np.max(embedding_scores):.4f}")
        print(f"   Ø§Ù„Ø£Ø¯Ù†Ù‰: {np.min(embedding_scores):.4f}")
        
        print(f"\nğŸ¯ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Cross-Encoder Scores:")
        print(f"   Ø§Ù„Ù…ØªÙˆØ³Ø·: {np.mean(cross_scores):.4f}")
        print(f"   Ø§Ù„Ø£Ø¹Ù„Ù‰: {np.max(cross_scores):.4f}")
        print(f"   Ø§Ù„Ø£Ø¯Ù†Ù‰: {np.min(cross_scores):.4f}")
        
        print(f"\nğŸ† Ø£ÙØ¶Ù„ 3 Ù…Ø±Ø´Ø­ÙŠÙ†:")
        for i, cv in enumerate(ranked_cvs[:3], 1):
            print(f"   {i}. {cv.cv.name} - Ø§Ù„Ø¯Ø±Ø¬Ø©: {cv.final_score:.4f}")
        
        print(f"\nğŸ“‰ Ø£Ø³ÙˆØ£ 3 Ù…Ø±Ø´Ø­ÙŠÙ†:")
        for i, cv in enumerate(ranked_cvs[-3:], len(ranked_cvs)-2):
            print(f"   {i}. {cv.cv.name} - Ø§Ù„Ø¯Ø±Ø¬Ø©: {cv.final_score:.4f}")
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙØ¬ÙˆØ§Øª
        print(f"\nğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙØ¬ÙˆØ§Øª:")
        excellent = sum(1 for cv in ranked_cvs if cv.final_score >= 2.0)
        good = sum(1 for cv in ranked_cvs if 0 <= cv.final_score < 2.0)
        weak = sum(1 for cv in ranked_cvs if cv.final_score < 0)
        
        print(f"   Ù…Ù…ØªØ§Ø² (>= 2.0): {excellent} Ù…Ø±Ø´Ø­")
        print(f"   Ø¬ÙŠØ¯ (0 - 2.0): {good} Ù…Ø±Ø´Ø­")
        print(f"   Ø¶Ø¹ÙŠÙ (< 0): {weak} Ù…Ø±Ø´Ø­")


# =============================================================================
# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
# =============================================================================

def main():
    """Ù…Ø«Ø§Ù„ Ø¹Ù…Ù„ÙŠ Ø¹Ù„Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ø¸Ø§Ù…"""
    
    # 1. Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙˆØ¸ÙŠÙØ©
    job = JobPosting(
        title="Senior Python Developer",
        description="""
        We are looking for an experienced Python developer to join our team.
        You will work on building scalable web applications using Django and FastAPI.
        Experience with machine learning and NLP is a plus.
        """,
        requirements="""
        - 5+ years of Python development experience
        - Strong knowledge of Django/FastAPI
        - Experience with PostgreSQL and Redis
        - Familiarity with Docker and Kubernetes
        - Good understanding of ML/NLP concepts
        - Excellent problem-solving skills
        """
    )
    
    # 2. Ø¥Ù†Ø´Ø§Ø¡ Ø³ÙŠØ± Ø°Ø§ØªÙŠØ© ØªØ¬Ø±ÙŠØ¨ÙŠØ©
    cvs = [
        CV(
            id="CV001",
            name="Ahmed Mohamed",
            content="""
            Senior Software Engineer with 6 years of experience in Python development.
            Expert in Django, FastAPI, and RESTful APIs. Built multiple scalable web applications
            serving millions of users. Proficient in PostgreSQL, Redis, and MongoDB.
            Experience with Docker, Kubernetes, and AWS. Strong background in machine learning
            and natural language processing. Led team of 5 developers in previous role.
            Skills: Python, Django, FastAPI, PostgreSQL, Redis, Docker, Kubernetes, ML, NLP, AWS
            """,
            email="ahmed@example.com",
            phone="+20 123 456 7890"
        ),
        CV(
            id="CV002",
            name="Sara Ali",
            content="""
            Python Developer with 3 years of experience. Worked primarily with Flask and Django.
            Good knowledge of SQL databases and basic understanding of Docker.
            Recent graduate with Master's degree in Computer Science.
            Interested in learning more about cloud technologies.
            Skills: Python, Django, Flask, MySQL, Git, Basic Docker
            """,
            email="sara@example.com",
            phone="+20 100 111 2222"
        ),
        CV(
            id="CV003",
            name="Omar Hassan",
            content="""
            Full Stack Developer with 7 years experience. Expert in Python, JavaScript, React.
            Built enterprise applications using Django and Node.js. Strong DevOps skills
            including Docker, Kubernetes, CI/CD pipelines. Experience with ML model deployment
            and MLOps. Contributed to several open-source NLP projects. AWS Certified Solutions Architect.
            Skills: Python, Django, FastAPI, React, Node.js, PostgreSQL, Redis, Docker, Kubernetes, ML, NLP, AWS, MLOps
            """,
            email="omar@example.com",
            phone="+20 122 333 4444"
        ),
        CV(
            id="CV004",
            name="Fatima Khalil",
            content="""
            Junior Python Developer with 1 year of experience. Knowledge of basic Python
            and Flask framework. Completed online courses in web development.
            Eager to learn and grow in the field. Strong academic background.
            Skills: Python, Flask, HTML, CSS, JavaScript, Git
            """,
            email="fatima@example.com",
            phone="+20 111 222 3333"
        ),
        CV(
            id="CV005",
            name="Khaled Ibrahim",
            content="""
            AI/ML Engineer with 5 years experience specializing in NLP and deep learning.
            Proficient in Python, TensorFlow, PyTorch, and scikit-learn. Built chatbots
            and text classification systems. Good knowledge of FastAPI for model serving.
            Experience with Docker and basic DevOps. Published research papers in NLP.
            Skills: Python, TensorFlow, PyTorch, scikit-learn, FastAPI, NLP, Deep Learning, Docker
            """,
            email="khaled@example.com",
            phone="+20 155 666 7777"
        ),
        CV(
            id="CV006",
            name="Layla Hussein",
            content="""
            Backend Developer with 4 years experience. Specialized in Python and Go.
            Built microservices architecture using FastAPI and gRPC. Good experience with
            distributed systems and message queues (RabbitMQ, Kafka). Knowledge of PostgreSQL,
            MongoDB, and Redis. Familiar with Docker and Kubernetes.
            Skills: Python, Go, FastAPI, gRPC, PostgreSQL, MongoDB, Redis, Docker, Kubernetes, Microservices
            """,
            email="layla@example.com",
            phone="+20 101 888 9999"
        ),
        CV(
            id="CV007",
            name="Youssef Mahmoud",
            content="""
            Tech Lead with 8 years of Python experience. Led multiple teams in building
            large-scale Django applications. Expert in microservices architecture with FastAPI.
            Extensive experience with PostgreSQL optimization and Redis clustering.
            Kubernetes certified administrator with 3 years production experience.
            Managed ML pipelines for NLP projects including sentiment analysis and text classification.
            Skills: Python, Django, FastAPI, PostgreSQL, Redis, Docker, Kubernetes, ML, NLP, AWS, Microservices
            """,
            email="youssef@example.com",
            phone="+20 133 444 5555"
        ),
        CV(
            id="CV008", 
            name="Nadia Salem",
            content="""
            Mid-level Python Developer with 4 years experience. Strong in Django development
            and REST API design. Good knowledge of PostgreSQL and basic Redis usage.
            Some experience with Docker containers but limited Kubernetes exposure.
            Basic understanding of machine learning concepts from university courses.
            Quick learner and strong problem-solving abilities.
            Skills: Python, Django, Flask, PostgreSQL, Redis, Docker, Git, REST APIs
            """,
            email="nadia@example.com",
            phone="+20 144 555 6666"
        ),
        CV(
            id="CV009",
            name="Mohammed Abdel-Rahman",
            content="""
            Junior Developer with 6 months internship experience. Learned Python through
            online courses and bootcamps. Basic knowledge of Django framework.
            Familiar with SQL databases but no production experience with PostgreSQL or Redis.
            Eager to learn and develop skills in web development and machine learning.
            Skills: Python, Django Basics, SQL, HTML/CSS, Git
            """,
            email="mohammed@example.com",
            phone="+20 155 666 7777"
        ),
        CV(
            id="CV010",
            name="Hana El-Sayed",
            content="""
            Frontend Developer with 2 years React experience. Some Python knowledge
            from personal projects but no professional backend development experience.
            Built small Flask applications for learning purposes. Strong in JavaScript
            and modern frontend frameworks. Looking to transition to full-stack development.
            Skills: JavaScript, React, HTML/CSS, Python Basics, Flask Basics
            """,
            email="hana@example.com",
            phone="+20 166 777 8888"
        ),
        CV(
            id="CV011",
            name="Tarek Nasser",
            content="""
            Senior Java Developer with 10 years enterprise experience. Recently learned
            Python for data analysis and automation scripts. No professional Django/FastAPI
            experience but strong software engineering fundamentals. Experience with
            containerization and cloud platforms. Quick to learn new technologies.
            Skills: Java, Spring Boot, Python, SQL, Docker, AWS, System Design
            """,
            email="tarek@example.com",
            phone="+20 177 888 9999"
        ),
        CV(
            id="CV012",
            name="Rania Fawzy",
            content="""
            Data Scientist with 4 years ML/NLP experience. Strong Python skills with
            focus on data analysis and model development. Some experience with FastAPI
            for model deployment. Limited knowledge of Django and traditional web development.
            Good with PostgreSQL for data storage. Strong problem-solving and analytical skills.
            Skills: Python, Machine Learning, NLP, FastAPI, PostgreSQL, Pandas, Scikit-learn, Docker
            """,
            email="rania@example.com",
            phone="+20 188 999 0000"
        )
    ]
    
    # 3. ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
    # ØªØ£ÙƒØ¯ Ù…Ù† ØªØ´ØºÙŠÙ„ Ollama Ø£ÙˆÙ„Ø§Ù‹: ollama serve
    # ÙˆØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: ollama pull gemma2 && ollama pull nomic-embed-text
    
    try:
        system = CVRankingSystem(
            ollama_url="http://localhost:11434",
            use_llm=True,  # ØªÙØ¹ÙŠÙ„ Gemma Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
            top_k_bi_encoder=10  # Ø¹Ø¯Ø¯ Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ù…Ø¨Ø¯Ø¦ÙŠØ©
        )
        
        # 4. ØªØ±ØªÙŠØ¨ Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ©
        ranked_results = system.rank_cvs(job, cvs, use_llm_analysis=True)
        
        # 5. Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        system.print_results(ranked_results, top_n=12)  # Ø¹Ø±Ø¶ Ø§Ù„ÙƒÙ„
        
        # 5.5 ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        system.analyze_ranking(ranked_results)
        
        # 6. Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        system.save_results(ranked_results)
        
    except Exception as e:
        print(f"\nâŒ Ø­Ø¯Ø« Ø®Ø·Ø£: {str(e)}")
        print("\nğŸ’¡ ØªØ£ÙƒØ¯ Ù…Ù†:")
        print("   1. ØªØ´ØºÙŠÙ„ Ollama: ollama serve")
        print("   2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©:")
        print("      - ollama pull gemma2:2b")
        print("      - ollama pull nomic-embed-text")
        print("\nğŸ“ Ù…Ù„Ø§Ø­Ø¸Ø§Øª:")
        print("   - Embedding Score: ÙŠÙ‚ÙŠØ³ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø³Ø·Ø­ÙŠ (Cosine Similarity)")
        print("   - Cross-Encoder Score: ÙŠÙ‚ÙŠØ³ Ø§Ù„Ù…Ù„Ø§Ø¡Ù…Ø© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© (Ø£Ø¯Ù‚ ÙˆØ£Ù‡Ù…)")
        print("   - Ø§Ù„Ø¯Ø±Ø¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© = Cross-Encoder Score (Ø§Ù„Ø£Ø³Ø§Ø³ ÙÙŠ Ø§Ù„ØªØ±ØªÙŠØ¨)")
        print("   - Ø¯Ø±Ø¬Ø© Ù…ÙˆØ¬Ø¨Ø© Ø¹Ø§Ù„ÙŠØ© (>2) = Ù…Ù…ØªØ§Ø² | (0-2) = Ø¬ÙŠØ¯ | Ø³Ø§Ù„Ø¨Ø© = Ø¶Ø¹ÙŠÙ")


if __name__ == "__main__":
    main()